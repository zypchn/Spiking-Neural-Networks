{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install snntorch -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbgVq9z-Jp4L",
        "outputId": "d6a26389-91ed-417b-ebc4-d3f515d2a4e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# snnTorch\n",
        "import snntorch as snn\n",
        "from snntorch import spikeplot as splt\n",
        "\n",
        "# pyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Vq2C0tfNJTLc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader args\n",
        "batch_size = 128\n",
        "data_path = \"/data/cifar10\"\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaC15HAIJq4Y",
        "outputId": "1e3f46e5-c700-4781-caf1-a25223de9b95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, ), (0.5, ))\n",
        "])"
      ],
      "metadata": {
        "id": "DtGyWzTeLhwS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import datasets\n",
        "cifar_train = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
        "cifar_test = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "# create DataLoaders\n",
        "train_loader = DataLoader(cifar_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(cifar_test, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQHelzz_N8Wl",
        "outputId": "ba56862d-afbe-4809-a74a-24580cd312e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /data/cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 37.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/cifar10/cifar-10-python.tar.gz to /data/cifar10\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Network Architecture\n",
        "num_inputs = 32 * 32\n",
        "num_hidden = 2000\n",
        "num_outputs = 10\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps = 25\n",
        "beta = 0.9"
      ],
      "metadata": {
        "id": "CWUoaqdMO6bZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Network\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Initialize layers\n",
        "    self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "    self.lif1 = snn.Leaky(beta=beta)\n",
        "    self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "    self.lif2 = snn.Leaky(beta=beta)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Initialize hidden states at t=0\n",
        "    mem1 = self.lif1.init_leaky()\n",
        "    mem2 = self.lif2.init_leaky()\n",
        "\n",
        "    # record the final layer\n",
        "    spk2_rec = []\n",
        "    mem2_rec = []\n",
        "\n",
        "    for step in range(num_steps):\n",
        "      cur1 = self.fc1(x)\n",
        "      spk1, mem1 = self.lif1(cur1, mem1)\n",
        "      cur2 = self.fc2(spk1)\n",
        "      spk2, mem2 = self.lif2(cur2, mem2)\n",
        "      spk2_rec.append(spk2)\n",
        "      mem2_rec.append(mem2)\n",
        "\n",
        "    return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)"
      ],
      "metadata": {
        "id": "ju17p0q-PLqt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the network onto CUDA if available\n",
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "nj_L5n2rSJPF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the SNN\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=4e-3, betas=(0.9, 0.999))\n",
        "\n",
        "num_epochs = 1\n",
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(num_epochs):\n",
        "  train_batch = iter(train_loader)\n",
        "\n",
        "  # Minibatch training loop\n",
        "  for data, targets in train_batch:\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    net.train()\n",
        "    spk_rec, _ = net(data.flatten(1))\n",
        "\n",
        "    # initialize the loss & sum over time\n",
        "    loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "    loss_val += loss(spk_rec.sum(0), targets)\n",
        "\n",
        "    # Gradient calculation + weight update\n",
        "    optimizer.zero_grad()\n",
        "    loss_val.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Store loss history for future plotting\n",
        "    loss_hist.append(loss_val.item())\n",
        "\n",
        "    # Print train/test loss/acc\n",
        "    if (counter % 10 == 0):\n",
        "      print(f\"Iteration : {counter} \\t Train Loss : {loss_val.item()}\")\n",
        "    counter += 1\n",
        "\n",
        "    if (counter == 100):\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HWL2XO-SPNu",
        "outputId": "35f6d8d6-3296-4535-b6d9-94bed23e0b0c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration : 0 \t Train Loss : 2.5993261337280273\n",
            "Iteration : 10 \t Train Loss : 2.381847620010376\n",
            "Iteration : 20 \t Train Loss : 2.3025853633880615\n",
            "Iteration : 30 \t Train Loss : 2.3025853633880615\n",
            "Iteration : 40 \t Train Loss : 2.3025853633880615\n",
            "Iteration : 50 \t Train Loss : 2.3025853633880615\n",
            "Iteration : 60 \t Train Loss : 2.3025853633880615\n",
            "Iteration : 70 \t Train Loss : 2.3025853633880615\n",
            "Iteration : 80 \t Train Loss : 2.3025853633880615\n",
            "Iteration : 90 \t Train Loss : 2.3025853633880615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_accuracy(model, dataloader):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    running_len = 0\n",
        "    running_acc = 0\n",
        "\n",
        "    for data, targets in iter(dataloader):\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      spk_rec, _ = model(data.flatten(1))\n",
        "      spike_count = spk_rec.sum(0)\n",
        "      _, max_spike = spike_count.max(1)\n",
        "\n",
        "      # correct classes for one batch\n",
        "      num_correct = (max_spike == targets).sum()\n",
        "\n",
        "      # total accuracy\n",
        "      running_len += len(targets)\n",
        "      running_acc += num_correct\n",
        "\n",
        "    acc = (running_acc / running_len)\n",
        "\n",
        "    return acc.item()"
      ],
      "metadata": {
        "id": "uLujQGDuTjh4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = measure_accuracy(net, test_loader)\n",
        "print(f\"Test set accuracy : {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNLRijD0UiNJ",
        "outputId": "8077d18c-7b8d-4c18-db75-d0c18801c96f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy : 0.09985977411270142\n"
          ]
        }
      ]
    }
  ]
}